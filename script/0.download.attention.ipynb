{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media Cloud: Measuring Attention\n",
    "================================\n",
    "- Reference: https://github.com/mediacloud/api-tutorial-notebooks/blob/main/MC02%20-%20attention.ipynb\n",
    "- Media Ids Query: https://search.mediacloud.org/sources/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.5.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[SUCCESS] MC API Key found.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[1;32mSUCCESS\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m MC API Key found.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up your API key and import needed things\n",
    "import os, mediacloud.api\n",
    "from importlib.metadata import version\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "import datetime as dt\n",
    "from IPython.display import JSON, display\n",
    "import bokeh.io\n",
    "from rich import print as pp\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=4, verbose=0)\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook(hide_banner=True)\n",
    "\n",
    "MC_API_KEY = os.getenv(\"MEDIA_CLOUD_API_KEY\")\n",
    "if MC_API_KEY is None:\n",
    "    try:\n",
    "        with open(\"../config/media.cloud.key\") as f:\n",
    "            MC_API_KEY = f.read().strip()\n",
    "        pp(\"[bold green][SUCCESS] MC API Key found.[/bold green]\")\n",
    "    except FileNotFoundError:\n",
    "        pp(\n",
    "            \"[bold red][ERROR] MC API key not found. Check ENV 'MEDIA_CLOUD_API_KEY' or file './config/media.cloud.key'[/bold red]\"\n",
    "        )\n",
    "else:\n",
    "    pp(\"[bold green][SUCCESS] MC API Key found.[/bold green]\")\n",
    "search_api = mediacloud.api.SearchApi(MC_API_KEY)\n",
    "# pp(f\"[gray][INFO] Using Media Cloud python client v{version('mediacloud')}[/gray]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Stories\n",
    "\n",
    "Story counts are fine, but often what you really want is the story themselves. Note that **we cannot provide story content** due to copyright restrictions. However, you can get a list of all the URLs and then fetch them yourself. We can also return word counts down to the story level (see the \"language\" notebook for more info on that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 28136,\n",
       "  'name': 'hannity.com',\n",
       "  'url_search_string': None,\n",
       "  'label': 'The Sean Hannity Show',\n",
       "  'homepage': 'http://www.hannity.com/',\n",
       "  'notes': None,\n",
       "  'platform': 'online_news',\n",
       "  'stories_per_week': 56,\n",
       "  'first_story': None,\n",
       "  'created_at': '2022-12-23T17:43:28.547804Z',\n",
       "  'modified_at': '2024-08-31T13:46:53.492705Z',\n",
       "  'pub_country': None,\n",
       "  'pub_state': None,\n",
       "  'primary_language': 'en',\n",
       "  'media_type': None,\n",
       "  'collection_count': 9}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email.mime import base\n",
    "import requests\n",
    "\n",
    "\n",
    "def qury_media_id(media_name: str = \"nytimes\"):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url=\"https://search.mediacloud.org/api/sources/sources/\",\n",
    "            params={\n",
    "                \"limit\": \"3\",\n",
    "                \"name\": media_name,\n",
    "            },\n",
    "            headers={\n",
    "                \"Cookie\": \"csrftoken=qqQVYfPizRLDITAtYCMn4ShmotfrK69T; sessionid=nk9ykemged6ukcvfjgfsg63p8l93p7ra\",\n",
    "            },\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            # print(response.json())\n",
    "            return response.json()[\"results\"]\n",
    "        else:\n",
    "            pp(f\"[red]ERROR: {response.status_code}[/red]\")\n",
    "    except requests.exceptions.RequestException:\n",
    "        pp(\"[red]HTTP Request failed[/red]\")\n",
    "\n",
    "\n",
    "# test\n",
    "qury_media_id(\"Sean Hannity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf949b09877497cbd506aaaa598ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e028f595214167b25c91fee27ecc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_media_id = pd.read_csv(\n",
    "    \"/home/rongxin/data/sync/trump-exposure/scripts/media-cloud-search/data/meta/Collection-34412234-United States - National-sources-20240907062857.csv\"\n",
    ").drop(\n",
    "    columns=[\n",
    "        \"url_search_string\",\n",
    "        \"notes\",\n",
    "        \"platform\",\n",
    "        \"first_story\",\n",
    "        \"pub_country\",\n",
    "        \"media_type\",\n",
    "        \"pub_state\",\n",
    "    ]\n",
    ")\n",
    "df_media_id[\"primary_language\"] = df_media_id[\"primary_language\"].fillna(\"\")\n",
    "df_media_id[\"name_clean\"] = df_media_id[\"name\"].parallel_apply(\n",
    "    lambda x: x.lower().split(\".\")[0]\n",
    ")\n",
    "\n",
    "name_mapping = {\n",
    "    \"abcnews\": \"abc\",\n",
    "    \"cbsnews\": \"cbs\",\n",
    "    \"theguardian\": \"guardian\",\n",
    "    \"huffingtonpost\": \"hp\",\n",
    "    \"nypost\": \"nyp\",\n",
    "    \"nytimes\": \"nyt\",\n",
    "    \"usatoday\": \"usa\",\n",
    "    \"washingtonpost\": \"wp\",\n",
    "    \"breitbart\": \"bb\",\n",
    "    \"businessinsider\": \"bi\",\n",
    "    \"dailycaller\": \"caller\",\n",
    "    \"foxnews\": \"fox\",\n",
    "    \"nbcnews\": \"nbc\",\n",
    "    \"politico\": \"pol\",\n",
    "    \"buzzfeed\": \"buzz\",\n",
    "    \"theguardian\": \"guard\",\n",
    "    \"newsweek\": \"week\",\n",
    "}\n",
    "df_media_id[\"name_clean\"] = df_media_id[\"name\"].parallel_apply(\n",
    "    lambda x: x.lower().split(\".\")[0]\n",
    ")\n",
    "df_media_id[\"name_clean\"] = df_media_id[\"name_clean\"].replace(name_mapping)\n",
    "df_media_id[\"stories_per_week\"] = df_media_id[\"stories_per_week\"].fillna(-1).astype(int)\n",
    "df_media_id.to_csv(\n",
    "    \"../data/meta/Collection-34412234-United States - National-sources-20240907062857-cleaned.csv\",\n",
    "    index=False,\n",
    ")\n",
    "# df_media_id.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150d74c76fe24cd4b73530cc57c27364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=8), Label(value='0 / 8'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> [Warning] </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">26</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> outlets; Washington Examiner and The Hill have no records on media cloud.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m \u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33mWarning\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m26\u001b[0m\u001b[1;33m outlets; Washington Examiner and The Hill have no records on media cloud.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>media</th>\n",
       "      <th>name_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19260</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>ABC</td>\n",
       "      <td>abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18897</td>\n",
       "      <td>bbc.co.uk</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>bbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19334</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>bb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            name      media name_clean\n",
       "0  19260  abcnews.go.com        ABC        abc\n",
       "1  18897       bbc.co.uk   BBC News        bbc\n",
       "2  19334   breitbart.com  Breitbart         bb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_media_ideo = pd.read_csv(\n",
    "    \"/home/rongxin/data/sync/trump-exposure/scripts/media-cloud-search/data/ideology/media_ideo.csv\"\n",
    ")\n",
    "df_media_ideo[\"name_clean\"] = df_media_ideo[\"media\"].parallel_apply(\n",
    "    lambda x: x.lower().split(\"u_\")[1]\n",
    ")\n",
    "# df_media_ideo.head()\n",
    "df_media_id = (\n",
    "    pd.merge(df_media_id, df_media_ideo, on=\"name_clean\", how=\"outer\")\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_media_id[\"id\"] = df_media_id[\"id\"].astype(int)\n",
    "df_media_id = df_media_id[[\"id\", \"name\", \"medianame\", \"name_clean\"]]\n",
    "medium_not_listed = [\n",
    "    [18897, \"bbc.co.uk\", \"BBC News\", \"bbc\"],\n",
    "    # [2, \"Washington Examiner\", \"exam\"], # no records on media cloud\n",
    "    # [3, \"The Hill\", \"hill\"],  # no records on media cloud\n",
    "    [28136, \"hannity.com\", \"Sean Hannity\", \"sean\"],\n",
    "]\n",
    "medium_not_listed = pd.DataFrame(\n",
    "    medium_not_listed, columns=[\"id\", \"name\", \"medianame\", \"name_clean\"]\n",
    ")\n",
    "df_media_id = (\n",
    "    pd.concat([df_media_id, medium_not_listed])\n",
    "    .rename(columns={\"medianame\": \"media\"})\n",
    "    .sort_values(by=\"name\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "pp(\n",
    "    f\"[bold yellow] [Warning] {len(df_media_id)} outlets; Washington Examiner and The Hill have no records on media cloud.[/bold yellow]\"\n",
    ")\n",
    "df_media_id.to_csv(\n",
    "    \"../data/meta/cloud.ideo.mapping.csv\",\n",
    "    index=False,\n",
    ")\n",
    "df_media_id.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to detect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13423010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_media_id_working(id: int = 2, query='\"climate change\"'):\n",
    "    try:\n",
    "        start_date = dt.date(2023, 11, 1)\n",
    "        end_date = dt.date(2023, 12, 1)\n",
    "        sources = [id]\n",
    "        result = search_api.story_count(query, start_date, end_date, source_ids=sources)\n",
    "        return int(result[\"total\"])\n",
    "    except Exception as e:\n",
    "        pp(f\"[red]ERROR: {e}[/red]\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "check_media_id_working(1, '\"the\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if ids work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>media</th>\n",
       "      <th>name_clean</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>314</td>\n",
       "      <td>huffingtonpost.com</td>\n",
       "      <td>HuffPost</td>\n",
       "      <td>hp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                name     media name_clean  total\n",
       "10  314  huffingtonpost.com  HuffPost         hp      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_media_id[\"total\"] = df_media_id[\"id\"].progress_apply(\n",
    "    lambda x: check_media_id_working(x)\n",
    ")\n",
    "df_media_id[df_media_id[\"total\"] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> [SUCCESS] </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">25</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> outlets; Washington Examiner, The Hill, and HuffPost have no records on media cloud.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mSUCCESS\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m25\u001b[0m\u001b[1;32m outlets; Washington Examiner, The Hill, and HuffPost have no records on media cloud.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_media_id = df_media_id[df_media_id.name_clean != \"hp\"]\n",
    "\n",
    "df_media_id.to_csv(\n",
    "    \"../data/meta/cloud.ideo.mapping.csv\",\n",
    "    index=False,\n",
    ")\n",
    "pp(\n",
    "    f\"[bold green] [SUCCESS] {len(df_media_id)} outlets; Washington Examiner, The Hill, and HuffPost have no records on media cloud.[/bold green]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export media ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_ids = sorted(df_media_id[\"id\"].tolist())\n",
    "media_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Found </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">71255</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> stories</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFound \u001b[0m\u001b[1;32m71255\u001b[0m\u001b[1;32m stories\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '7853cd2a17dea3793aa3f90f7836eae5f80d4d657c2d39cc5f26210a24d66696',\n",
       "  'media_name': 'bbc.co.uk',\n",
       "  'media_url': 'bbc.co.uk',\n",
       "  'title': 'A quick guide to smoking bans across the world',\n",
       "  'publish_date': '2023-11-27',\n",
       "  'url': 'https://www.bbc.co.uk/news/uk-67545363',\n",
       "  'language': 'en',\n",
       "  'indexed_date': '2024-08-30'},\n",
       " {'id': '0fc0218db50dde7663b1b183e56a05a6b97ec6d8d4b11b04fefa86291e3c4005',\n",
       "  'media_name': 'buzzfeed.com',\n",
       "  'media_url': 'buzzfeed.com',\n",
       "  'title': 'Over, Under, Or Accurately Rated \"Evermore\" Songs Poll',\n",
       "  'publish_date': '2023-11-27',\n",
       "  'url': 'https://www.buzzfeed.com/paigeswiftie/evermore-songs-overrated-underrated-poll',\n",
       "  'language': 'en',\n",
       "  'indexed_date': '2024-08-23'},\n",
       " {'id': 'cc1ebfd683325dac32b7cc0bd9553ff2051b60086d5838b3b7e6aff7f28596bc',\n",
       "  'media_name': 'foxnews.com',\n",
       "  'media_url': 'foxnews.com',\n",
       "  'title': 'What to know about Legionnaires’ disease, the lung infection reported in New Hampshire',\n",
       "  'publish_date': '2023-11-06',\n",
       "  'url': 'https://www.foxnews.com/health/what-know-about-legionnaires-disease-lung-infection-reported-new-hampshire',\n",
       "  'language': 'en',\n",
       "  'indexed_date': '2024-08-15'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's fetch all the stories matching our query on one day\n",
    "my_query = '\"the\"'  # note the double quotes used to indicate use of the whole phrase\n",
    "start_date = dt.date(2023, 11, 1)\n",
    "end_date = dt.date(2023, 12, 1)\n",
    "all_stories = []\n",
    "US_NATIONAL_COLLECTION = 34412234\n",
    "more_stories = True\n",
    "pagination_token = None\n",
    "\n",
    "while more_stories:\n",
    "    page, pagination_token = search_api.story_list(\n",
    "        my_query,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        # collection_ids=[US_NATIONAL_COLLECTION],\n",
    "        # source_ids=sources,\n",
    "        source_ids=media_ids,\n",
    "        pagination_token=pagination_token,\n",
    "    )\n",
    "    all_stories += page\n",
    "    more_stories = pagination_token is not None\n",
    "\n",
    "\n",
    "def clean_story_dates(story):\n",
    "    story[\"publish_date\"] = str(story[\"publish_date\"].strftime(\"%Y-%m-%d\"))\n",
    "    story[\"indexed_date\"] = str(story[\"indexed_date\"].strftime(\"%Y-%m-%d\"))\n",
    "    return story\n",
    "\n",
    "\n",
    "all_stories = [clean_story_dates(story) for story in all_stories]\n",
    "pp(f\"[bold green]Found {len(all_stories)} stories[/bold green]\")\n",
    "all_stories[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>media_name</th>\n",
       "      <th>media_url</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>indexed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7853cd2a17dea3793aa3f90f7836eae5f80d4d657c2d39...</td>\n",
       "      <td>bbc.co.uk</td>\n",
       "      <td>bbc.co.uk</td>\n",
       "      <td>A quick guide to smoking bans across the world</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-67545363</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0fc0218db50dde7663b1b183e56a05a6b97ec6d8d4b11b...</td>\n",
       "      <td>buzzfeed.com</td>\n",
       "      <td>buzzfeed.com</td>\n",
       "      <td>Over, Under, Or Accurately Rated \"Evermore\" So...</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>https://www.buzzfeed.com/paigeswiftie/evermore...</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc1ebfd683325dac32b7cc0bd9553ff2051b60086d5838...</td>\n",
       "      <td>foxnews.com</td>\n",
       "      <td>foxnews.com</td>\n",
       "      <td>What to know about Legionnaires’ disease, the ...</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>https://www.foxnews.com/health/what-know-about...</td>\n",
       "      <td>en</td>\n",
       "      <td>2024-08-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id    media_name  \\\n",
       "0  7853cd2a17dea3793aa3f90f7836eae5f80d4d657c2d39...     bbc.co.uk   \n",
       "1  0fc0218db50dde7663b1b183e56a05a6b97ec6d8d4b11b...  buzzfeed.com   \n",
       "2  cc1ebfd683325dac32b7cc0bd9553ff2051b60086d5838...   foxnews.com   \n",
       "\n",
       "      media_url                                              title  \\\n",
       "0     bbc.co.uk     A quick guide to smoking bans across the world   \n",
       "1  buzzfeed.com  Over, Under, Or Accurately Rated \"Evermore\" So...   \n",
       "2   foxnews.com  What to know about Legionnaires’ disease, the ...   \n",
       "\n",
       "  publish_date                                                url language  \\\n",
       "0   2023-11-27             https://www.bbc.co.uk/news/uk-67545363       en   \n",
       "1   2023-11-27  https://www.buzzfeed.com/paigeswiftie/evermore...       en   \n",
       "2   2023-11-06  https://www.foxnews.com/health/what-know-about...       en   \n",
       "\n",
       "  indexed_date  \n",
       "0   2024-08-30  \n",
       "1   2024-08-23  \n",
       "2   2024-08-15  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stories = pd.DataFrame(all_stories)\n",
    "df_stories.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "media_name\n",
       "cbsnews.com            13368\n",
       "foxnews.com             7699\n",
       "bbc.co.uk               7633\n",
       "wsj.com                 6944\n",
       "nypost.com              6650\n",
       "washingtonpost.com      5761\n",
       "newsweek.com            3815\n",
       "abcnews.go.com          3749\n",
       "businessinsider.com     3035\n",
       "dailycaller.com         2516\n",
       "buzzfeed.com            2175\n",
       "breitbart.com           1922\n",
       "nbcnews.com             1580\n",
       "politico.com             991\n",
       "pbs.org                  852\n",
       "usatoday.com             774\n",
       "time.com                 575\n",
       "msnbc.com                514\n",
       "vice.com                 404\n",
       "vox.com                  166\n",
       "hannity.com              132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stories.value_counts(\"media_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stories.to_csv(\"../data/stories/stories.the.all.by.id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelized by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'donald trump'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_query(\n",
    "    query: str = \"Donald Trump OR Donald J Trump OR RealDonaldTrump OR donald trump OR donald j trump OR realdonaldtrump\",\n",
    "):\n",
    "    query = query.lower()\n",
    "    if \"congress\" in query:\n",
    "        return \"congress\"\n",
    "    elif \"senate\" in query:\n",
    "        return \"senate\"\n",
    "    elif \" or \" in query:\n",
    "        query = query.split(\" or \")[0]\n",
    "        return query\n",
    "        # if \" \" in query:\n",
    "        #     return query.split(\" \")[0]\n",
    "        # else:\n",
    "        #     return query\n",
    "    elif \" and \" in query:\n",
    "        query = query.split(\" and \")[0]\n",
    "        return query\n",
    "        # if \" \" in query:\n",
    "        #     return query.split(\" \")[0]\n",
    "        # else:\n",
    "        #     return query\n",
    "    elif \" \" in query:\n",
    "        return query.split(\" \")[0]\n",
    "    else:\n",
    "        return query\n",
    "\n",
    "\n",
    "def query_by_ids(\n",
    "    ids: list,\n",
    "    query: str = \"the\",\n",
    "    start_date: dt.date = dt.date(2023, 11, 1),\n",
    "    end_date: dt.date = dt.date(2023, 12, 1),\n",
    "):\n",
    "    data_folder = f\"../data/stories/by.ids/{split_query(query)}\"\n",
    "    try:\n",
    "        # let's fetch all the stories matching our query on one day\n",
    "        my_query = f\"{query}\"  # note the double quotes used to indicate use of the whole phrase\n",
    "        all_stories = []\n",
    "        more_stories = True\n",
    "        pagination_token = None\n",
    "\n",
    "        while more_stories:\n",
    "            page, pagination_token = search_api.story_list(\n",
    "                my_query,\n",
    "                start_date,\n",
    "                end_date,\n",
    "                source_ids=ids,\n",
    "                pagination_token=pagination_token,\n",
    "            )\n",
    "            all_stories += page\n",
    "            more_stories = pagination_token is not None\n",
    "\n",
    "        def clean_story_dates(story):\n",
    "            story[\"publish_date\"] = str(story[\"publish_date\"].strftime(\"%Y-%m-%d\"))\n",
    "            story[\"indexed_date\"] = str(story[\"indexed_date\"].strftime(\"%Y-%m-%d\"))\n",
    "            return story\n",
    "\n",
    "        all_stories = [clean_story_dates(story) for story in all_stories]\n",
    "        pp(f\"[bold green]Found {len(all_stories)}  by ids.[/bold green]\")\n",
    "        if not os.path.exists(f\"../data/stories/by.ids/{split_query(query)}\"):\n",
    "            os.makedirs(f\"../data/stories/by.ids/{split_query(query)}\")\n",
    "        pd.DataFrame(all_stories).to_csv(\n",
    "            f\"../data/stories/by.ids/{split_query(query)}/{str(start_date)}.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "        return len(all_stories)\n",
    "    except Exception as e:\n",
    "        pp(f\"[red]ERROR: {e}[/red], pass\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def query_by_collections(\n",
    "    collections=[34412234],\n",
    "    query: str = \"the\",\n",
    "    start_date: dt.date = dt.date(2023, 11, 1),\n",
    "    end_date: dt.date = dt.date(2023, 12, 1),\n",
    "):\n",
    "    # let's fetch all the stories matching our query on one day\n",
    "    my_query = (\n",
    "        f\"{query}\"  # note the double quotes used to indicate use of the whole phrase\n",
    "    )\n",
    "    all_stories = []\n",
    "    more_stories = True\n",
    "    pagination_token = None\n",
    "\n",
    "    while more_stories:\n",
    "        page, pagination_token = search_api.story_list(\n",
    "            my_query,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            collection_ids=collections,\n",
    "            pagination_token=pagination_token,\n",
    "        )\n",
    "        all_stories += page\n",
    "        more_stories = pagination_token is not None\n",
    "\n",
    "    def clean_story_dates(story):\n",
    "        story[\"publish_date\"] = str(story[\"publish_date\"].strftime(\"%Y-%m-%d\"))\n",
    "        story[\"indexed_date\"] = str(story[\"indexed_date\"].strftime(\"%Y-%m-%d\"))\n",
    "        return story\n",
    "\n",
    "    all_stories = [clean_story_dates(story) for story in all_stories]\n",
    "    if not os.path.exists(f\"../data/stories/by.collections/{split_query(query)}\"):\n",
    "        os.makedirs(f\"../data/stories/by.collections/{split_query(query)}\")\n",
    "    pd.DataFrame(all_stories).to_csv(\n",
    "        f\"../data/stories/by.collections/{split_query(query)}/{str(start_date)}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    pp(f\"[bold green]Found {len(all_stories)} stories by collections. [/bold green]\")\n",
    "    return len(all_stories)\n",
    "\n",
    "\n",
    "split_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">731</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> dates</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m \u001b[0m\u001b[1;32m731\u001b[0m\u001b[1;32m dates\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0  2020-01-07\n",
       "1  2020-01-08\n",
       "2  2020-01-09"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# dates = [dt.date(2020, 1, day) for day in range(1, 3)]\n",
    "dates = pd.date_range(\n",
    "    dt.date(2020, 1, 7), dt.date(2022, 1, 7) - timedelta(days=1), freq=\"d\"\n",
    ")\n",
    "df_dates = pd.DataFrame(dates, columns=[\"date\"])\n",
    "df_dates[\"date\"] = df_dates[\"date\"].dt.date\n",
    "pp(f\"[bold green] {len(df_dates)} dates[/bold green]\")\n",
    "df_dates.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Donald Trump OR Donald J Trump OR RealDonaldTrump OR donald trump OR donald j trump OR realdonaldtrump\",\n",
    "    \"Joe Biden OR joebiden\",\n",
    "    \"Mike Pence OR mikepence\",\n",
    "    \"Howie Hawkins OR howiehawkins2020\",\n",
    "    \"Kamala Harris OR kamalaharris\",\n",
    "    \"Jo Jorgensen OR JoForLiberty\",\n",
    "    \"Angela Nicole Walker OR Angela Walker\",\n",
    "    \"Spike Cohen OR literallyspikecohe\",\n",
    "    \"Republican Party OR GOP OR republicanparty OR The Republican\",\n",
    "    \"Democratic Party OR Democrats OR TheDemocrats OR The Democratic\",\n",
    "    \"2020 United States presidential election OR #election OR presidential election\",\n",
    "    \"white house OR whitehouse\",\n",
    "    \"United States Congress OR congress\",\n",
    "    \"United States Senate OR senate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca13df90f0184507a6cce70ca30c42f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [04:58<1:04:38, 298.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879dd6eabaa94ba1a7c8cd893df39f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [38:42<4:22:42, 1313.56s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5931e1077b5e40c1850dd537cc26d907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [55:02<3:32:53, 1161.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853e463b13af4c88b8e64336c3695ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [58:14<2:09:45, 778.51s/it] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b1fe8e35e64fe09a3a704ff726d305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [1:04:57<1:36:29, 643.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d48c34a268e4e6092e145d2c29ac46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [1:08:35<1:06:29, 498.66s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a78cd2df71441bbd41704d97be24e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [1:11:47<46:29, 398.45s/it]  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac752f04e0cf4fbca885c48a450ca821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [1:18:49<40:34, 405.69s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cbd6978a8f48b6824231a08bc61ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [1:41:01<57:56, 695.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0c61580a6e45ff8462598519737f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [1:59:13<54:31, 817.87s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eeb8fec079420b94a9d890bb14447b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [2:03:26<32:14, 644.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f675948c86a048b3b71d73f1598a642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [2:43:04<39:04, 1172.06s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d7645b130944bd953bdead471cab80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [3:14:57<23:16, 1396.74s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4cf53413c24f6e9ece3c609d786da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=183), Label(value='0 / 183'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [3:45:47<00:00, 967.66s/it] \n",
      "100%|██████████| 14/14 [3:45:47<00:00, 967.66s/it] \n"
     ]
    }
   ],
   "source": [
    "for query in tqdm(queries):\n",
    "    df_dates[f\"{query}\"] = df_dates[\"date\"].parallel_apply(\n",
    "        lambda x: query_by_collections(query=query, start_date=x, end_date=x)\n",
    "    )\n",
    "    df_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
